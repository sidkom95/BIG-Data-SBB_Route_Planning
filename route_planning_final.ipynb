{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final route planning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Now that we have improved the initial by computing multiple paths and adding probability computation, we will build the final algorithm._\n",
    "\n",
    "_The user enters the departure time, departure location, final stop and a desired probability._\n",
    "\n",
    "_We then compute the top 3 routes with their respective probability._\n",
    "\n",
    "### 1. There are directly some possible routes:\n",
    "_If there are some paths, we output them directly such that it satisfies the desired probability._\n",
    "\n",
    "### 2. There are no routes\n",
    "_We reject the desired probability and considers it as a failure. The route closest to the user requirement is still returned._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'group100_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9205</td><td>application_1589299642358_3772</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3772/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3772_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9226</td><td>application_1589299642358_3793</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3793/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3793_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9244</td><td>application_1589299642358_3813</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3813/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3813_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9250</td><td>application_1589299642358_3819</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3819/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3819_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9252</td><td>application_1589299642358_3821</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3821/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3821_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9255</td><td>application_1589299642358_3824</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3824/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3824_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9267</td><td>application_1589299642358_3836</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3836/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3836_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9269</td><td>application_1589299642358_3839</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3839/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3839_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9271</td><td>application_1589299642358_3842</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3842/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3842_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9285</td><td>application_1589299642358_3856</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3856/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3856_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9286</td><td>application_1589299642358_3857</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3857/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3857_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9287</td><td>application_1589299642358_3858</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3858/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3858_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9292</td><td>application_1589299642358_3866</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3866/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3866_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9294</td><td>application_1589299642358_3868</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3868/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3868_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9295</td><td>application_1589299642358_3869</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3869/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3869_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9300</td><td>application_1589299642358_3877</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3877/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster066.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3877_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9301</td><td>application_1589299642358_3878</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3878/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3878_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9302</td><td>application_1589299642358_3879</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3879/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3879_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9303</td><td>application_1589299642358_3880</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3880/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3880_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9305</td><td>application_1589299642358_3882</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3882/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3882_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9306</td><td>application_1589299642358_3883</td><td>pyspark</td><td>dead</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/cluster/app/application_1589299642358_3883\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster054.iccluster.epfl.ch:8188/applicationhistory/logs/iccluster069.iccluster.epfl.ch:45454/container_e06_1589299642358_3883_01_000001/container_e06_1589299642358_3883_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9307</td><td>application_1589299642358_3884</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3884/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3884_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9308</td><td>application_1589299642358_3885</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3885/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3885_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9309</td><td>application_1589299642358_3886</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3886/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3886_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9310</td><td>application_1589299642358_3887</td><td>pyspark</td><td>starting</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3887/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3887_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\": \"group100_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9311</td><td>application_1589299642358_3888</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3888/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3888_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "username = 'mjouve'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import time, datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading previously obtained dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stops = spark.read.orc(\"/user/{}/zurich_stops.orc\".format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reachable_pair_grouped = spark.read.orc(\"/user/{}/reachable_pair_grouped.orc\".format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_times = spark.read.orc(\"/user/{}/stop_times_filtered.orc\".format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "connexions = spark.read.orc(\"/user/{}/connexions.orc\".format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_footpaths_dict(reachable_pair_df):\n",
    "    \"\"\"\n",
    "    Given a pyspark Dataframe of reachable pairs grouped,\n",
    "    returns the footpaths dictionary used by our algorithm\n",
    "    \"\"\"\n",
    "    return dict(((row.id_1, row.destinations) for row in reachable_pair_df.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_datetime(str_time):\n",
    "    \"\"\"\n",
    "    Given a string representing a time (format 'H:M:s', H: hour, M: minute, s:second), convert it to a datetime object\n",
    "    \"\"\"\n",
    "    hour, minute, second = str_time.split(':')\n",
    "    \n",
    "    # convert it to int and remove potential errors by taking a modulo\n",
    "    hour = int(hour) % 24\n",
    "    minute = int(minute) % 60\n",
    "    second = int(second) % 60\n",
    "    \n",
    "    # the year, month and day are dummies heres\n",
    "    return datetime(year=2020, month=1, day=1, hour=hour, minute=minute, second=second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sort_connexions(connexions_df, departure = True):\n",
    "    \"\"\"\n",
    "    Given a pyspark DataFrame of connexions, returns an array of sorted connexions in ascending order of departure\n",
    "    if departure = True, else in descending order of arrival\n",
    "    \"\"\"\n",
    "\n",
    "    connexions_array = [{'departure_location': row.stop_id_1, \n",
    "                         'departure_time': to_datetime(row.departure_time_1), \n",
    "                         'arrival_location': row.stop_id_2, \n",
    "                         'arrival_time': to_datetime(row.arrival_time_2), \n",
    "                         'trip_id': row.trip_id} for row in connexions_df.collect()]\n",
    "    \n",
    "    if departure:\n",
    "        sorted_connexions = sorted(connexions_array, key = (lambda tup: tup['departure_time']))\n",
    "    \n",
    "    else:\n",
    "        sorted_connexions = sorted(connexions_array, key = (lambda tup: tup['arrival_time']), reverse = True)\n",
    "        \n",
    "    return sorted_connexions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute probability given lambda and a time left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for lambdaa we pass the arrival_delay median\n",
    "def proba_trip(lambdaa, time_left): #time left in seconds\n",
    "    \n",
    "    # This is the average lambda for all possible entries, and we will use it as a default value\n",
    "    default_value = 0.023447352748076224\n",
    "    \n",
    "    if lambdaa == -9999:\n",
    "        lambdaa = default_value\n",
    "    \n",
    "    if lambdaa < 0:\n",
    "        return 1\n",
    "    else:\n",
    "        \n",
    "        return 1 - np.exp(- lambdaa * time_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating arrival times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def updates_times_dict_given_departure_top_K_with_proba(times, sorted_connexions, lambda_dict, footpaths, departure_location, departure_time, final_location, K, desired_probability, max_time):\n",
    "    \"\"\"\n",
    "    Given an initialized times dictionary, the array of sorted connexion, the footpaths dictionary\n",
    "    a departure_location given as a stop_id (str),\n",
    "    a departure time (datetime object),\n",
    "    the final destination,\n",
    "    the number of routes (K),\n",
    "    the desired confidence probability and\n",
    "    a maximum time not to exceed\n",
    "    updates the times dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # initalize the departure\n",
    "    times[departure_location][0] = ( (departure_time, 1, None, None) )\n",
    "    \n",
    "    # cheminement delay is 0 for the first connexion taken\n",
    "    cheminement_delay = timedelta(seconds = 0)\n",
    "\n",
    "\n",
    "    # Initalize a dictionary of trips taken. For each trip already taken, \n",
    "    # we map it to the first departure location and departure time where we could have taken this trip. \n",
    "    # Returns None if the key is not assigned to another value thanks to defaultdict.\n",
    "    trips_taken = defaultdict(lambda: None)\n",
    "\n",
    "    # Iterate over connexions in sorted order\n",
    "    for c in sorted_connexions:\n",
    "    \n",
    "        # trip_id of the current connexion\n",
    "        trip_id = c['trip_id']\n",
    "    \n",
    "        # departure location of the current connexion\n",
    "        departure_location = c['departure_location']\n",
    "    \n",
    "        # departure time of the current connexion\n",
    "        departure_time = c['departure_time']\n",
    "    \n",
    "        # arrival location of the current connexion\n",
    "        arrival_location = c['arrival_location']\n",
    "    \n",
    "        # arrival time of the current connexion\n",
    "        arrival_time = c['arrival_time']\n",
    "    \n",
    "        # If current trip could have been taken earlier\n",
    "        if trips_taken[trip_id]:\n",
    "            \n",
    "            \n",
    "            # obtain data about this current trip (where we could have taken it and when)\n",
    "            trip_data = trips_taken[trip_id]\n",
    "        \n",
    "            # obtain array\n",
    "            arrival_array = times[arrival_location]\n",
    "            \n",
    "            # access old proba\n",
    "            if times[trip_data[0]][0][2] == None:\n",
    "                old_proba = 1\n",
    "                new_proba = 1\n",
    "            else:\n",
    "                prev_connex_data = times[trip_data[0]][0][2]                   \n",
    "                old_proba = times[trip_data[0]][0][1]\n",
    "                prev_arrival_time = prev_connex_data['arrival_time']\n",
    "                \n",
    "                \n",
    "                if prev_connex_data.get('walking', None):\n",
    "                    prev_arrival_time = prev_arrival_time - timedelta(seconds = prev_connex_data['walking'])\n",
    "                    prev_arrival = prev_connex_data['departure_location']\n",
    "                else:\n",
    "                    prev_arrival = prev_connex_data['arrival_location']\n",
    "            \n",
    "                # compute the lambda of the exponential distribution given the arrival location and arrival time\n",
    "                lambdaa = lambda_dict[(prev_arrival, str(prev_arrival_time.time()))]\n",
    "                \n",
    "                # take into consideration the walking time\n",
    "                walking_time = prev_connex_data.get('walking', 0)\n",
    "                \n",
    "                # compute probability to catch the connexion\n",
    "                new_proba = proba_trip(lambdaa, (trip_data[1] - prev_arrival_time - timedelta(seconds = 120) -  timedelta(seconds = int(walking_time))).seconds)\n",
    "                \n",
    "    \n",
    "            # if it is the final location we store multiple paths\n",
    "            if arrival_location == final_location and len(arrival_array) < K:\n",
    "                \n",
    "                # if we satisfy the confidence\n",
    "                if new_proba >= desired_probability:\n",
    "                    \n",
    "                    # if we respect the maximal time\n",
    "                    if arrival_time <= max_time:\n",
    "                \n",
    "                        arrival_array.append((arrival_time, old_proba * new_proba, {'departure_location': trip_data[0],\n",
    "                                                              'departure_time': trip_data[1],\n",
    "                                                              'arrival_location':arrival_location,\n",
    "                                                              'arrival_time': arrival_time,\n",
    "                                                              'trip_id': trip_id}, new_proba))\n",
    "                \n",
    "                        arrival_array.sort(key = (lambda tup: tup[0]))\n",
    "            \n",
    "            # otherwise update the entry\n",
    "            elif arrival_time < times[arrival_location][-1][0]:\n",
    "                \n",
    "                if new_proba >= desired_probability:\n",
    "                    \n",
    "                    if arrival_time <= max_time:\n",
    "                        # update arrival time as well as connexion data for this arrival location\n",
    "                        times[arrival_location][-1] = (arrival_time, old_proba * new_proba, {'departure_location': trip_data[0],\n",
    "                                                              'departure_time': trip_data[1],\n",
    "                                                              'arrival_location':arrival_location,\n",
    "                                                              'arrival_time': arrival_time,\n",
    "                                                              'trip_id': trip_id}, new_proba)\n",
    "                \n",
    "                        arrival_array.sort(key = (lambda tup: tup[0]))\n",
    "            \n",
    "            # obtain the stops reachable by walking\n",
    "            reachable_stops_walking = footpaths.get(arrival_location, None)\n",
    "            \n",
    "            \n",
    "            if reachable_stops_walking:\n",
    "                \n",
    "                # for each possible destination\n",
    "                for destination in reachable_stops_walking:\n",
    "                    \n",
    "                    # obtain the stop_id\n",
    "                    location = destination[0]\n",
    "                    \n",
    "                    # obtain the walk duration from arrival_location (convert it to float)\n",
    "                    walking_time = float(destination[1])\n",
    "                    \n",
    "                    # compute the new arrival time if using this path\n",
    "                    new_arrival_time = arrival_time + timedelta(seconds = walking_time)\n",
    "                    \n",
    "                    # obtain the current arrival time\n",
    "                    curr_arrival_time_array = times[location]\n",
    "                      \n",
    "                    if location == final_location and len(curr_arrival_time_array) < K:\n",
    "                        \n",
    "                        if new_proba >= desired_probability:\n",
    "                        \n",
    "                            if new_arrival_time <= max_time:\n",
    "                                curr_arrival_time_array.append((new_arrival_time, old_proba * new_proba, {'departure_location': arrival_location,\n",
    "                                                              'departure_time': arrival_time,\n",
    "                                                              'arrival_location':location,\n",
    "                                                              'arrival_time': new_arrival_time,\n",
    "                                                              'trip_id': trip_id,\n",
    "                                                              'walking': walking_time}, new_proba))\n",
    "                        \n",
    "                                curr_arrival_time_array.sort(key = (lambda tup: tup[0]))\n",
    "                    \n",
    "                    \n",
    "                    # if it improves the current best arrival time, we update our dictionary\n",
    "                    elif new_arrival_time < curr_arrival_time_array[-1][0]:\n",
    "                        \n",
    "                        \n",
    "                        if new_proba >= desired_probability:\n",
    "                            if new_arrival_time <= max_time:\n",
    "                                curr_arrival_time_array[-1] = (new_arrival_time, old_proba * new_proba, {'departure_location': arrival_location,\n",
    "                                                              'departure_time': arrival_time,\n",
    "                                                              'arrival_location':location,\n",
    "                                                              'arrival_time': new_arrival_time,\n",
    "                                                              'trip_id': trip_id,\n",
    "                                                              'walking': walking_time}, new_proba)\n",
    "                        \n",
    "                                curr_arrival_time_array.sort(key = (lambda tup: tup[0]))\n",
    "    \n",
    "        # if we can take this connexion\n",
    "        elif (times[departure_location][0][0] + cheminement_delay) <= departure_time:\n",
    "            \n",
    "            # delay is now 2 minutes\n",
    "            cheminement_delay = timedelta(seconds = 120)\n",
    "\n",
    "            # update trips taken with this new trip\n",
    "            trips_taken[trip_id] = (departure_location, departure_time)\n",
    "        \n",
    "            # get arrival array\n",
    "            arrival_location_array = times[arrival_location]\n",
    "            \n",
    "            # access old proba\n",
    "            if times[departure_location][0][2] == None:\n",
    "                old_proba = 1\n",
    "                new_proba = 1\n",
    "            else:\n",
    "                prev_connex_data = times[departure_location][0][2]\n",
    "                    \n",
    "                old_proba = times[departure_location][0][1]\n",
    "                prev_arrival_time = prev_connex_data['arrival_time']\n",
    "                    \n",
    "                if prev_connex_data.get('walking', None):\n",
    "                    prev_arrival_time = prev_arrival_time - timedelta(seconds = prev_connex_data['walking'])\n",
    "                    prev_arrival = prev_connex_data['departure_location']\n",
    "                else:\n",
    "                    prev_arrival = prev_connex_data['arrival_location']\n",
    "                    \n",
    "                time_str = str(prev_arrival_time.time())\n",
    "                \n",
    "                # getting the lambda for the exponential distribution\n",
    "                lambdaa = lambda_dict[(prev_arrival, time_str)]\n",
    "                \n",
    "                # take into consideration walking time\n",
    "                walking_time = prev_connex_data.get('walking', 0)\n",
    "                \n",
    "                # calculate proba to get this connexion\n",
    "                new_proba = proba_trip(lambdaa, (departure_time - prev_arrival_time - timedelta(seconds = 120) - timedelta(seconds = int(walking_time))).seconds)\n",
    "            \n",
    "            # if if is the final location, we store more than one path\n",
    "            if arrival_location == final_location and len(arrival_location_array) < K:\n",
    "                \n",
    "                    if new_proba >= desired_probability:\n",
    "                        if arrival_time <= max_time:\n",
    "                            arrival_location_array.append((arrival_time, old_proba * new_proba, {'departure_location': departure_location,\n",
    "                                                              'departure_time': departure_time,\n",
    "                                                              'arrival_location':arrival_location,\n",
    "                                                              'arrival_time': arrival_time,\n",
    "                                                              'trip_id': trip_id}, new_proba)  )\n",
    "                \n",
    "                            arrival_location_array.sort(key=(lambda tup: tup[0]))\n",
    "                \n",
    "            # if the arrival time is better than the current best\n",
    "            elif arrival_time < times[arrival_location][-1][0]:\n",
    "                \n",
    "                if new_proba >= desired_probability:\n",
    "            \n",
    "                    # update the best time for the arrival location\n",
    "                    if arrival_time <= max_time:\n",
    "                        arrival_location_array[-1] = (arrival_time, old_proba * new_proba, c, new_proba)  \n",
    "                \n",
    "                        arrival_location_array.sort(key=(lambda tup: tup[0]))\n",
    "            \n",
    "            # obtain the stops reachable by walking\n",
    "            reachable_stops_walking = footpaths.get(arrival_location, None) \n",
    "            \n",
    "            if reachable_stops_walking:\n",
    "                \n",
    "                # for each possible destination\n",
    "                for destination in reachable_stops_walking:\n",
    "                    \n",
    "                    # obtain the stop_id\n",
    "                    location = destination[0]\n",
    "                    \n",
    "                    # obtain the walk duration from arrival_location (convert it to float)\n",
    "                    walking_time = float(destination[1])\n",
    "                    \n",
    "                    # compute the new arrival time if using this path\n",
    "                    new_arrival_time = arrival_time + timedelta(seconds = walking_time)\n",
    "                    \n",
    "                    # obtain the current arrival time\n",
    "                    curr_arrival_time_array = times[location]\n",
    "                      \n",
    "                    if location == final_location and len(curr_arrival_time_array) < K:\n",
    "                        \n",
    "                        if new_proba >= desired_probability:\n",
    "                            \n",
    "                            if new_arrival_time <= max_time:\n",
    "                        \n",
    "                                curr_arrival_time_array.append((new_arrival_time, old_proba * new_proba, {'departure_location': arrival_location,\n",
    "                                                              'departure_time': arrival_time,\n",
    "                                                              'arrival_location':location,\n",
    "                                                              'arrival_time': new_arrival_time,\n",
    "                                                              'trip_id': trip_id,\n",
    "                                                              'walking': walking_time}, new_proba))\n",
    "                        \n",
    "                                curr_arrival_time_array.sort(key = (lambda tup: tup[0]))\n",
    "                    \n",
    "                    \n",
    "                    # if it improves the current best arrival time, we update our dictionary\n",
    "                    elif new_arrival_time < curr_arrival_time_array[-1][0]:\n",
    "                        \n",
    "                        if new_proba >= desired_probability:\n",
    "                            \n",
    "                            if new_arrival_time <= max_time:\n",
    "                                curr_arrival_time_array[-1] = (new_arrival_time, old_proba * new_proba, {'departure_location': arrival_location,\n",
    "                                                              'departure_time': arrival_time,\n",
    "                                                              'arrival_location':location,\n",
    "                                                              'arrival_time': new_arrival_time,\n",
    "                                                              'trip_id': trip_id,\n",
    "                                                              'walking': walking_time}, new_proba)\n",
    "                        \n",
    "                                curr_arrival_time_array.sort(key = (lambda tup: tup[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find possible routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_routes(connexions, stops_array, lambda_dict, footpaths, departure_stop, departure_time, arrival_stop, desired_probability, max_time = '23:30:00'):\n",
    "    \n",
    "    hour, minute, second = departure_time.split(':')\n",
    "    hour = int(hour)\n",
    "    minute = int(minute)\n",
    "    second = int(second)\n",
    "    \n",
    "    departure_time_datetime = datetime(year=2020, month=1, day=1, hour=hour, minute=minute, second=second)\n",
    "    \n",
    "    hour, minute, second = max_time.split(':')\n",
    "    hour = int(hour)\n",
    "    minute = int(minute)\n",
    "    second = int(second)\n",
    "    \n",
    "    max_time_datetime = datetime(year=2020, month=1, day=1, hour=hour, minute=minute, second=second)\n",
    "    \n",
    "        \n",
    "    # initialized time\n",
    "    times = dict(((row.stop_id, \n",
    "               [(datetime(year=2020, month=1, day=6, hour=23, minute=59, second = 59), 1, None, None)]) \n",
    "              for row in stops_array))\n",
    "        \n",
    "        \n",
    "    updates_times_dict_given_departure_top_K_with_proba(times,\n",
    "                                                        connexions,\n",
    "                                                        lambda_dict,\n",
    "                                                        footpaths, \n",
    "                                                        departure_stop, \n",
    "                                                        departure_time_datetime, \n",
    "                                                        arrival_stop, K, \n",
    "                                                        desired_proba,\n",
    "                                                        max_time_datetime)\n",
    "        \n",
    "    successful = []\n",
    "    not_enough = []\n",
    "        \n",
    "    for output in times[arrival_stop]:\n",
    "        if output[0] != datetime(year=2020, month=1, day=6, hour=23, minute=59, second = 59):\n",
    "\n",
    "            if output[1] >= desired_probability:\n",
    "                successful.append(output)\n",
    "            else:\n",
    "                not_enough.append(output)\n",
    "        \n",
    "    if len(successful) == 0 and len(not_enough) == 0:\n",
    "        print('Failure to find such a path')\n",
    "        return\n",
    "            \n",
    "    if len(successful) > 0:\n",
    "        print('Successful - printing routes...\\n')\n",
    "            \n",
    "        for i, connexion_data in enumerate(successful):\n",
    "            paths = print_route(times, connexion_data, departure_stop)\n",
    "            print('Route {nb}:'.format(nb = i+1))\n",
    "            for path in paths:\n",
    "                print(path)\n",
    "            print('\\n')\n",
    "        return\n",
    "            \n",
    "    else:\n",
    "        max_prob = -1\n",
    "        max_route = None\n",
    "        \n",
    "        for path in not_enough:\n",
    "            prob = path[1]\n",
    "            \n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                max_route = path\n",
    "            \n",
    "            \n",
    "        print('Failure to find such a path')\n",
    "        print('However the route closest to your requirements is:')\n",
    "        paths = print_route(times, max_route, departure_stop)\n",
    "        for path in paths:\n",
    "            print(path)\n",
    "            print('\\n')\n",
    "        return       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given a possible route, print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_route(times, last_connexion, departure_stop):\n",
    "    paths = []\n",
    "    \n",
    "    current_stop_data = last_connexion\n",
    "    current_stop = None\n",
    "    \n",
    "    while current_stop != departure_stop:\n",
    "        \n",
    "        current_connexion = current_stop_data[2]\n",
    "        \n",
    "        proba = current_stop_data[1]\n",
    "        \n",
    "        current_stop = current_connexion['departure_location']\n",
    "        arrival_location = current_connexion['arrival_location']\n",
    "        trip = current_connexion['trip_id']\n",
    "        \n",
    "        walking = current_connexion.get('walking', None)\n",
    "        \n",
    "        if walking:\n",
    "            path = 'Walking during {s}s'.format(s = int(walking)) + ' from {d} to {a}'.format(d = current_stop, a = arrival_location)\n",
    "        \n",
    "        else:\n",
    "            path = 'From {d_l} (at {d_t}) to {a_l} (at {a_t}) using trip: {t}. Current probability = {p}'.format(d_l = current_stop,\n",
    "                                                                                      d_t = current_connexion['departure_time'].time(),\n",
    "                                                                                      a_l = arrival_location,\n",
    "                                                                                      a_t = current_connexion['arrival_time'].time(),\n",
    "                                                                                      t = current_connexion['trip_id'],\n",
    "                                                                                      p = proba)\n",
    "        \n",
    "        paths.append(path)\n",
    "        \n",
    "        \n",
    "        current_stop_data = times[current_stop][0]\n",
    "    \n",
    "    return paths[::-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "footpaths = compute_footpaths_dict(reachable_pair_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_connexions = sort_connexions(connexions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stops_array = stops.select(stops.stop_id).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictive_data = spark.read.orc(\"/user/{}/grouped_delay_lambdas.orc\".format('mjouve'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution_data = predictive_data.select(predictive_data.stop_id,\n",
    "                                           predictive_data.arrival_time,\n",
    "                                           predictive_data['lambda'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defaultdict storing for each pair (arrival_stop, arrival_time) a lambda computed by our predictive model, if not present returns the default value (average computed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is the average lambda for all possible entries, and we will use it as a default value\n",
    "default_value = 0.023447352748076224\n",
    "\n",
    "lambda_dict = defaultdict(lambda: default_value)\n",
    "\n",
    "for row in distribution_data.collect():\n",
    "    lambda_dict[(row.stop_id, row.arrival_time)] = row['lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "departure_stop = '8503000'\n",
    "departure_time = '12:05:00'\n",
    "arrival_stop = '8591049'\n",
    "\n",
    "# if we give a maximum time\n",
    "max_time = '12:30:00'\n",
    "K = 3\n",
    "\n",
    "desired_proba = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful - printing routes...\n",
      "\n",
      "Route 1:\n",
      "From 8503000 (at 12:05:00) to 8503006 (at 12:11:00) using trip: 32.TA.80-159-Y-j19-1.8.H. Current probability = 1\n",
      "Walking during 72s from 8503006 to 8580449\n",
      "From 8580449 (at 12:15:00) to 8591049 (at 12:24:00) using trip: 1914.TA.26-11-A-j19-1.27.R. Current probability = 0.783457744058\n",
      "\n",
      "\n",
      "Route 2:\n",
      "From 8503000 (at 12:07:00) to 8503310 (at 12:17:00) using trip: 20.TA.26-9-A-j19-1.2.H. Current probability = 1\n",
      "Walking during 70s from 8503310 to 8590620\n",
      "From 8590620 (at 12:23:00) to 8591049 (at 12:29:00) using trip: 168.TA.26-12-A-j19-1.2.H. Current probability = 0.915466308093"
     ]
    }
   ],
   "source": [
    "find_routes(sorted_connexions,\n",
    "            stops_array,\n",
    "            lambda_dict, \n",
    "            footpaths, \n",
    "            departure_stop, departure_time, arrival_stop, desired_proba, max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful - printing routes...\n",
      "\n",
      "Route 1:\n",
      "From 8503000 (at 12:05:00) to 8503006 (at 12:11:00) using trip: 32.TA.80-159-Y-j19-1.8.H. Current probability = 1\n",
      "Walking during 72s from 8503006 to 8580449\n",
      "From 8580449 (at 12:15:00) to 8591049 (at 12:24:00) using trip: 1914.TA.26-11-A-j19-1.27.R. Current probability = 0.783457744058\n",
      "\n",
      "\n",
      "Route 2:\n",
      "From 8503000 (at 12:07:00) to 8503310 (at 12:17:00) using trip: 20.TA.26-9-A-j19-1.2.H. Current probability = 1\n",
      "Walking during 70s from 8503310 to 8590620\n",
      "From 8590620 (at 12:23:00) to 8591049 (at 12:29:00) using trip: 168.TA.26-12-A-j19-1.2.H. Current probability = 0.915466308093\n",
      "\n",
      "\n",
      "Route 3:\n",
      "From 8503000 (at 12:05:00) to 8503006 (at 12:11:00) using trip: 32.TA.80-159-Y-j19-1.8.H. Current probability = 1\n",
      "Walking during 72s from 8503006 to 8580449\n",
      "From 8580449 (at 12:16:00) to 8591225 (at 12:21:00) using trip: 660.TA.26-787-j19-1.4.R. Current probability = 0.968013186502\n",
      "Walking during 556s from 8591225 to 8591049"
     ]
    }
   ],
   "source": [
    "# if we don't give a max_time\n",
    "find_routes(sorted_connexions,\n",
    "            stops_array,\n",
    "            lambda_dict, \n",
    "            footpaths, \n",
    "            departure_stop, departure_time, arrival_stop, desired_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
