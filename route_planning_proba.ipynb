{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Route planning with probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_While constructing our predictive model, we first made a version of the route planning with dummy probabilities._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'group100_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9204</td><td>application_1589299642358_3771</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3771/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3771_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9205</td><td>application_1589299642358_3772</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3772/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3772_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9216</td><td>application_1589299642358_3783</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3783/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3783_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9217</td><td>application_1589299642358_3784</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3784/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3784_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9226</td><td>application_1589299642358_3793</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3793/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3793_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9230</td><td>application_1589299642358_3797</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3797/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3797_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9232</td><td>application_1589299642358_3799</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3799/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3799_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9236</td><td>application_1589299642358_3804</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3804/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3804_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9237</td><td>application_1589299642358_3805</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3805/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3805_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9239</td><td>application_1589299642358_3808</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3808/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3808_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9244</td><td>application_1589299642358_3813</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3813/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3813_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9246</td><td>application_1589299642358_3815</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3815/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3815_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9248</td><td>application_1589299642358_3817</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3817/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3817_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9250</td><td>application_1589299642358_3819</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3819/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3819_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9252</td><td>application_1589299642358_3821</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3821/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3821_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9253</td><td>application_1589299642358_3822</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3822/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3822_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9254</td><td>application_1589299642358_3823</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3823/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3823_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9255</td><td>application_1589299642358_3824</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3824/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3824_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9256</td><td>application_1589299642358_3825</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3825/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3825_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9257</td><td>application_1589299642358_3826</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3826/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3826_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9258</td><td>application_1589299642358_3827</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3827/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3827_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9260</td><td>application_1589299642358_3829</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3829/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3829_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9261</td><td>application_1589299642358_3830</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3830/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3830_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9262</td><td>application_1589299642358_3831</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3831/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3831_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9263</td><td>application_1589299642358_3832</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3832/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3832_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9264</td><td>application_1589299642358_3833</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3833/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster071.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3833_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9265</td><td>application_1589299642358_3834</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3834/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3834_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9266</td><td>application_1589299642358_3835</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3835/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3835_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9267</td><td>application_1589299642358_3836</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3836/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3836_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9268</td><td>application_1589299642358_3837</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3837/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3837_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9269</td><td>application_1589299642358_3839</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3839/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster068.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3839_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9270</td><td>application_1589299642358_3841</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3841/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3841_01_000001/ebouille\">Link</a></td><td></td></tr><tr><td>9271</td><td>application_1589299642358_3842</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3842/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster065.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3842_01_000001/ebouille\">Link</a></td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\": \"group100_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>9272</td><td>application_1589299642358_3843</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_3843/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_3843_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "username = 'mjouve'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import time, datetime, timedelta\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading previously obtained dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stops = spark.read.orc(\"/user/{}/zurich_stops.orc\".format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reachable_pair_grouped = spark.read.orc(\"/user/{}/reachable_pair_grouped.orc\".format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_times = spark.read.orc(\"/user/{}/stop_times_filtered.orc\".format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "connexions = spark.read.orc(\"/user/{}/connexions.orc\".format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_footpaths_dict(reachable_pair_df):\n",
    "    \"\"\"\n",
    "    Given a pyspark Dataframe of reachable pairs grouped,\n",
    "    returns the footpaths dictionary used by our algorithm\n",
    "    \"\"\"\n",
    "    return dict(((row.id_1, row.destinations) for row in reachable_pair_df.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_datetime(str_time):\n",
    "    \"\"\"\n",
    "    Given a string representing a time (format 'H:M:s', H: hour, M: minute, s:second), convert it to a datetime object\n",
    "    \"\"\"\n",
    "    hour, minute, second = str_time.split(':')\n",
    "    \n",
    "    # convert it to int and remove potential errors by taking a modulo\n",
    "    hour = int(hour) % 24\n",
    "    minute = int(minute) % 60\n",
    "    second = int(second) % 60\n",
    "    \n",
    "    # the year, month and day are dummies heres\n",
    "    return datetime(year=2020, month=1, day=1, hour=hour, minute=minute, second=second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sort_connexions(connexions_df, departure = True):\n",
    "    \"\"\"\n",
    "    Given a pyspark DataFrame of connexions, returns an array of sorted connexions in ascending order of departure\n",
    "    if departure = True, else in descending order of arrival\n",
    "    \"\"\"\n",
    "\n",
    "    connexions_array = [{'departure_location': row.stop_id_1, \n",
    "                         'departure_time': to_datetime(row.departure_time_1), \n",
    "                         'arrival_location': row.stop_id_2, \n",
    "                         'arrival_time': to_datetime(row.arrival_time_2), \n",
    "                         'trip_id': row.trip_id} for row in connexions_df.collect()]\n",
    "    \n",
    "    if departure:\n",
    "        sorted_connexions = sorted(connexions_array, key = (lambda tup: tup['departure_time']))\n",
    "    \n",
    "    else:\n",
    "        sorted_connexions = sorted(connexions_array, key = (lambda tup: tup['arrival_time']), reverse = True)\n",
    "        \n",
    "    return sorted_connexions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy method for returning a probability given a lambda and a time_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for lambdaa we pass the arrival_delay median\n",
    "def proba_trip(lambdaa, time_left): #time left in seconds\n",
    "    if lambdaa < 0:\n",
    "        return 0.95\n",
    "    else:\n",
    "        \n",
    "        return 1 - np.exp(- lambdaa * time_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating arrival times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def updates_times_dict_given_departure_with_proba(times, sorted_connexions, footpaths, lambda_dict, departure_location, departure_time, desired_probability):\n",
    "    \"\"\"\n",
    "    Given an initialized times dictionary, the array of sorted connexion, the footpaths dictionary\n",
    "    a departure_location given as a stop_id (str),\n",
    "    and a departure time (datetime object)\n",
    "    updates the times dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    times[departure_location] = (departure_time, 1, None)\n",
    "\n",
    "    # Initalize a dictionary of trips taken. For each trip already taken, \n",
    "    # we map it to the first departure location and departure time where we could have taken this trip. \n",
    "    # Returns None if the key is not assigned to another value thanks to defaultdict.\n",
    "    trips_taken = defaultdict(lambda: None)\n",
    "\n",
    "    # Iterate over connexions in sorted order\n",
    "    for c in sorted_connexions:\n",
    "    \n",
    "        # trip_id of the current connexion\n",
    "        trip_id = c['trip_id']\n",
    "    \n",
    "        # departure location of the current connexion\n",
    "        departure_location = c['departure_location']\n",
    "    \n",
    "        # departure time of the current connexion\n",
    "        departure_time = c['departure_time']\n",
    "    \n",
    "        # arrival location of the current connexion\n",
    "        arrival_location = c['arrival_location']\n",
    "    \n",
    "        # arrival time of the current connexion\n",
    "        arrival_time = c['arrival_time']\n",
    "    \n",
    "        # If current trip could have been taken earlier\n",
    "        if trips_taken[trip_id]:\n",
    "        \n",
    "            # obtain data about this current trip (where we could have taken it and when)\n",
    "            trip_data = trips_taken[trip_id]\n",
    "        \n",
    "            # if arrival_time is earlier than the current best time assigned for this location\n",
    "            if arrival_time < times[arrival_location][0]:\n",
    "            \n",
    "                # access old proba\n",
    "                if times[trip_data[0]][2] == None:\n",
    "                    old_proba = 1\n",
    "                    new_proba = 1\n",
    "                else:\n",
    "                \n",
    "                    prev_connex_data = times[trip_data[0]][2]                   \n",
    "                    old_proba = times[trip_data[0]][1]\n",
    "                    prev_arrival_time = prev_connex_data['arrival_time']\n",
    "                    \n",
    "                    if prev_connex_data.get('walking', None):\n",
    "                        prev_arrival_time = prev_arrival_time - timedelta(seconds = prev_connex_data['walking'])\n",
    "                    \n",
    "                \n",
    "                    lambdaa = lambda_dict[(departure_location, prev_arrival_time)]\n",
    "                \n",
    "                    new_proba = proba_trip(lambdaa, (departure_time - prev_arrival_time).seconds)\n",
    "                    \n",
    "#                     print(old_proba * new_proba)\n",
    "                \n",
    "                \n",
    "                \n",
    "                if new_proba > desired_proba:\n",
    "                \n",
    "                    # update arrival time as well as connexion data for this arrival location\n",
    "                    times[arrival_location] = (arrival_time, old_proba * new_proba, {'departure_location': trip_data[0],\n",
    "                                                              'departure_time': trip_data[1],\n",
    "                                                              'arrival_location':arrival_location,\n",
    "                                                              'arrival_time': arrival_time,\n",
    "                                                              'trip_id': trip_id})\n",
    "            \n",
    "                # obtain the stops reachable by walking\n",
    "                reachable_stops_walking = footpaths.get(arrival_location, None)\n",
    "            \n",
    "            \n",
    "                if reachable_stops_walking:\n",
    "                \n",
    "                    # for each possible destination\n",
    "                    for destination in reachable_stops_walking:\n",
    "                    \n",
    "                        # obtain the stop_id\n",
    "                        location = destination[0]\n",
    "                    \n",
    "                        # obtain the current arrival time\n",
    "                        curr_arrival_time = times[location][0]    \n",
    "      \n",
    "                        # obtain the walk duration from arrival_location (convert it to float)\n",
    "                        walking_time = float(destination[1])\n",
    "                    \n",
    "                        # compute the new arrival time if using this path\n",
    "                        new_arrival_time = arrival_time + timedelta(seconds = walking_time)\n",
    "                    \n",
    "                    \n",
    "                        # if it improves the current best arrival time, we update our dictionary\n",
    "                        if new_arrival_time < curr_arrival_time:\n",
    "                            \n",
    "                            if new_proba > desired_proba:\n",
    "                                times[location] = (new_arrival_time, old_proba * new_proba, {'departure_location': arrival_location,\n",
    "                                                              'departure_time': arrival_time,\n",
    "                                                              'arrival_location':location,\n",
    "                                                              'arrival_time': new_arrival_time,\n",
    "                                                              'trip_id': trip_id,\n",
    "                                                              'walking': walking_time})\n",
    "        \n",
    "    \n",
    "        # if we can take this connexion\n",
    "        elif (times[departure_location][0] + timedelta(seconds = 120)) <= departure_time:\n",
    "\n",
    "            # update trips taken with this new trip\n",
    "            trips_taken[trip_id] = (departure_location, departure_time)\n",
    "        \n",
    "            # if the arrival time is better than the current best\n",
    "            if arrival_time < times[arrival_location][0]:\n",
    "                \n",
    "                \n",
    "                # access old proba\n",
    "                if times[departure_location][2] == None:\n",
    "                    old_proba = 1\n",
    "                    new_proba = 1\n",
    "                else:\n",
    "                    prev_connex_data = times[departure_location][2]\n",
    "                    \n",
    "                    old_proba = times[departure_location][1]\n",
    "                    prev_arrival_time = prev_connex_data['arrival_time']\n",
    "                    \n",
    "                    if prev_connex_data.get('walking', None):\n",
    "                        prev_arrival_time = prev_arrival_time - timedelta(seconds = prev_connex_data['walking'])\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                    lambdaa = lambda_dict[(departure_location, prev_arrival_time)]\n",
    "                \n",
    "                    new_proba = proba_trip(lambdaa, (departure_time - prev_arrival_time).seconds)\n",
    "                    \n",
    "#                     print(old_proba * new_proba)\n",
    "                \n",
    "                if new_proba > desired_proba:\n",
    "                \n",
    "                    # update the best time for the arrival location\n",
    "                    times[arrival_location] = (arrival_time, old_proba * new_proba, c)           \n",
    "            \n",
    "            \n",
    "                # obtain the stops reachable by walking\n",
    "                reachable_stops_walking = footpaths.get(arrival_location, None)\n",
    "                \n",
    "                \n",
    "                \n",
    "                if reachable_stops_walking:\n",
    "                \n",
    "                    # for each possible destination\n",
    "                    for destination in reachable_stops_walking:\n",
    "                    \n",
    "                        # obtain the stop_id\n",
    "                        location = destination[0]\n",
    "                    \n",
    "                        # obtain the current arrival time\n",
    "                        curr_arrival_time = times[location][0]    \n",
    "                      \n",
    "                        # obtain the walk duration from arrival_location (convert it to float)\n",
    "                        walking_time = float(destination[1])\n",
    "                    \n",
    "                        # compute the new arrival time if using this path\n",
    "                        new_arrival_time = arrival_time + timedelta(seconds = walking_time)\n",
    "                    \n",
    "                    \n",
    "                        \n",
    "                        # if it improves the current best arrival time, we update our dictionary\n",
    "                        if new_arrival_time < curr_arrival_time:\n",
    "                            \n",
    "                            if new_proba > desired_proba:\n",
    "                                times[location] = (new_arrival_time, old_proba * new_proba, {'departure_location': arrival_location,\n",
    "                                                              'departure_time': arrival_time,\n",
    "                                                              'arrival_location':location,\n",
    "                                                              'arrival_time': new_arrival_time,\n",
    "                                                              'trip_id': trip_id,\n",
    "                                                              'walking': walking_time})            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def backward_proba(departure_stop, arrival_stop, times):\n",
    "    \"\"\"\n",
    "    Returns a list of paths taken from departure_stop to arrival_stop given the times dictionary computed\n",
    "    \"\"\"\n",
    "    \n",
    "    paths = []\n",
    "    \n",
    "    current_stop_data = times[arrival_stop]\n",
    "    current_stop = None\n",
    "    \n",
    "    while current_stop != departure_stop:\n",
    "        \n",
    "        current_connexion = current_stop_data[2]\n",
    "        \n",
    "        proba = current_stop_data[1]\n",
    "        \n",
    "        current_stop = current_connexion['departure_location']\n",
    "        arrival_location = current_connexion['arrival_location']\n",
    "        trip = current_connexion['trip_id']\n",
    "        \n",
    "        walking = current_connexion.get('walking', None)\n",
    "        \n",
    "        if walking:\n",
    "            path = 'Walking during {s}s'.format(s = int(walking)) + ' from {d} to {a}'.format(d = current_stop, a = arrival_location)\n",
    "        \n",
    "        else:\n",
    "            path = 'From {d_l} (at {d_t}) to {a_l} (at {a_t}) using trip: {t}. Current probability = {p}'.format(d_l = current_stop,\n",
    "                                                                                      d_t = current_connexion['departure_time'].time(),\n",
    "                                                                                      a_l = arrival_location,\n",
    "                                                                                      a_t = current_connexion['arrival_time'].time(),\n",
    "                                                                                      t = current_connexion['trip_id'],\n",
    "                                                                                      p = proba)\n",
    "        \n",
    "        paths.append(path)\n",
    "        \n",
    "        \n",
    "        current_stop_data = times[current_stop]\n",
    "        \n",
    "    \n",
    "    return paths[::-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "footpaths = compute_footpaths_dict(reachable_pair_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_connexions = sort_connexions(connexions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defaultdict storing the lambda parameters for the prediction\n",
    "\n",
    "_Because it will always return -1, each probability returned by the method `proba_trip` will be 0.95._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lambda_dict = defaultdict(lambda: -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = dict(((row.stop_id, \n",
    "               (datetime(year=2020, month=1, day=6, hour=23, minute=59, second = 59), 1, None)) \n",
    "              for row in stops.select(stops.stop_id).collect()))\n",
    "\n",
    "\n",
    "departure_stop = '8503000'\n",
    "arrival_stop = '8591049'\n",
    "departure_time = '12:00:00'\n",
    "desired_proba = 0.9\n",
    "\n",
    "\n",
    "hour, minute, second = departure_time.split(':')\n",
    "hour = int(hour)\n",
    "minute = int(minute)\n",
    "second = int(second)\n",
    "    \n",
    "departure_time_datetime = datetime(year=2020, month=1, day=1, hour=hour, minute=minute, second=second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updates_times_dict_given_departure_with_proba(times, sorted_connexions, footpaths, lambda_dict, \n",
    "                                              departure_stop,\n",
    "                                              departure_time_datetime,\n",
    "                                              desired_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths = backward_proba('8503000', '8591049', times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 8503000 (at 12:05:00) to 8503006 (at 12:11:00) using trip: 32.TA.80-159-Y-j19-1.8.H. Current probability = 1\n",
      "Walking during 72s from 8503006 to 8580449\n",
      "From 8580449 (at 12:15:00) to 8591049 (at 12:24:00) using trip: 1914.TA.26-11-A-j19-1.27.R. Current probability = 0.95"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next step:\n",
    "\n",
    "_Now that our algorithm is ready to use probabilities, let's try to build our predictive model. You can see our thought process in the `predective_model.ipynb` notebook._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
